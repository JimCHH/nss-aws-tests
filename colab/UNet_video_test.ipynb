{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet_video_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x1001000/nss-aws-tests/blob/main/colab/UNet_video_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVaRhTdkN6so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5111b3b-c90e-4b2a-81c1-6a7ee8a08779"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "# # 獲取授權碼之後輸入即可連動雲端硬碟\n",
        "# data = pd.read_csv(\"/content/gdrive/My Drive/codev2/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2TX1Vlo2xve"
      },
      "source": [
        "需要新增存下影片檔名的code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8GGZNbQC_r1"
      },
      "source": [
        " happen to have an existing .py file in Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhCAmJQwKu-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab79d79-1253-4cb2-f5af-281ba379768b"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Jan 18 17:07:35 2021\n",
        " \n",
        "@author: lab70929\n",
        "\"\"\"\n",
        " \n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from unet import UNet\n",
        "import parameters\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        " \n",
        "start_time = time.time()\n",
        "device = torch.device(\"cuda\")\n",
        " \n",
        "def Unet_test(images, model, Size_X, Size_Y):\n",
        "    batch_size = len(images)\n",
        "    t = []\n",
        "    t1 = time.time()\n",
        "    inputImg = []\n",
        "    inputImg_BK = []\n",
        "    center_list = []\n",
        "    for image in images:\n",
        "        \n",
        "        image = cv2.resize(image, (Size_X, Size_Y), interpolation=cv2.INTER_CUBIC)\n",
        "        inputImg_BK.append(image.copy())  \n",
        "        image = image.astype(np.float32)/255\n",
        "        image = image[np.newaxis, :]\n",
        " \n",
        "        inputImg.append(image)\n",
        "    \n",
        "    inputImg = np.array(inputImg)\n",
        "        \n",
        "    t2 = time.time()\n",
        "    t.append(t2-t1)\n",
        "    \n",
        "    tf_images = torch.from_numpy(inputImg)\n",
        "    tf_images = tf_images.to(device)\n",
        "    output = model(tf_images)\n",
        "    output_bk = output[:, 0].clone().detach().cpu().numpy()\n",
        "    \n",
        "    t3 = time.time()\n",
        "    t.append(t3-t2)\n",
        "    \n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        temp = output_bk[i]\n",
        "        gt_temp = inputImg_BK[i]\n",
        "        ttt = output_bk[i]\n",
        "        ttt[ttt < 0.5] = 0\n",
        "        ttt[ttt >= 0.5] = 1\n",
        "        if np.count_nonzero(ttt) == 0:\n",
        "            temp[temp < 0.25] = 0\n",
        "            temp[temp >= 0.25] = 1\n",
        "        else:\n",
        "            temp[temp < 0.5] = 0\n",
        "            temp[temp >= 0.5] = 1\n",
        "    \n",
        "        ## Connected Component Analysis\n",
        "        if np.count_nonzero(temp) != 0:\n",
        "            _, labels, stats, center = cv2.connectedComponentsWithStats(temp[:, :].astype(np.uint8))\n",
        "    \n",
        "            stats = stats[1:, :]\n",
        "            pupil_candidate = np.argmax(stats[:, 4]) + 1\n",
        "            temp[:, :][labels != pupil_candidate] = 0\n",
        "            \n",
        "        gt_temp[temp == 1] = 255\n",
        "        output_bk[i] = temp\n",
        " \n",
        "        index = np.argwhere(temp == 1)\n",
        "        if index.shape != (0, 2):\n",
        "            x_center = np.average(index[:,0])\n",
        "            y_center = np.average(index[:,1])\n",
        "            center_list.append([x_center, y_center])\n",
        "        else:\n",
        "            center_list.append([0, 0])\n",
        "       \n",
        "    t4 = time.time()\n",
        "    t.append(t4-t3)\n",
        "    \n",
        "    return inputImg_BK, t, center_list\n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        "name_load_model = (\"/content/gdrive/My Drive/codev2/trained_model/UNet/\")\n",
        "cross_val_num = 18\n",
        " \n",
        "Size_X = parameters.Size_X\n",
        "Size_Y = parameters.Size_Y\n",
        " \n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        " \n",
        " \n",
        "model = UNet(n_channels=1, n_classes=1, bilinear=True)\n",
        "if os.path.exists(name_load_model):\n",
        "    load_saved_model_name = parameters.find_latest_model_name(name_load_model, cross_val_num)\n",
        "    model.load_state_dict(torch.load(load_saved_model_name))\n",
        "    print(parameters.C_GREEN + 'Check point Successfully Loaded' + parameters.C_END)\n",
        "else:\n",
        "    print(parameters.C_RED + 'Check point Not Found' + parameters.C_END)\n",
        " \n",
        " \n",
        "model.eval()\n",
        "model.to(device)\n",
        " \n",
        "#left_roi = [[176,0],[540,300]]\n",
        "#right_roi = [[750,0],[1130,340]]\n",
        "left_roi = []\n",
        "right_roi = []\n",
        " \n",
        "video_folder = (\"/content/gdrive/My Drive/codev2/Result/\") \n",
        "# video_folder = \"C:/Users/lab70929/Downloads/Debug_s7.2.5.1/Debug/Result/\"\n",
        "fps = []\n",
        "video_list = glob.glob(video_folder+\"*.mp4\")\n",
        "save_time = []\n",
        "#for video_name in video_list:\n",
        "video_name = video_list[0]\n",
        "output_name = video_name[:-4] + \"_tracking.mp4\"\n",
        " \n",
        "print(\"video_name = \", video_name)\n",
        " \n",
        "out = cv2.VideoWriter(output_name, fourcc, 210, (384, 144), 0)\n",
        "cap = cv2.VideoCapture(video_name)\n",
        "frame_count = 0\n",
        " \n",
        " \n",
        "batch_size = 16\n",
        "counter = 0\n",
        "images = []\n",
        "temp_image = []\n",
        "center_list = []\n",
        "left_center_list_H = []\n",
        "left_center_list_V = []\n",
        "right_center_list_H = []\n",
        "right_center_list_V = []\n",
        "t = []\n",
        "data = {'Left':{'Horizontal':{}, 'Vertical':{}}, 'Right':{'Horizontal':{}, 'Vertical':{}}, 'Timestamps':{}}\n",
        " \n",
        "while (cap.isOpened()):\n",
        "#    print(counter)\n",
        " \n",
        "    \n",
        "    \n",
        "    if counter<batch_size//2:\n",
        "        \n",
        "        ret, frame = cap.read()\n",
        "        if ret == False:\n",
        "            break\n",
        "    \n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        if left_roi ==[]:\n",
        "            left_eye = frame[:, :640]\n",
        "            right_eye = frame[:, 640:]\n",
        "        else:\n",
        "            left_eye = frame[left_roi[0][1]:left_roi[1][1], left_roi[0][0]:left_roi[1][0]]\n",
        "            right_eye = frame[right_roi[0][1]:right_roi[1][1], right_roi[0][0]:right_roi[1][0]]\n",
        "    \n",
        "        images.append(left_eye)\n",
        "        images.append(right_eye)\n",
        "        counter += 1\n",
        " \n",
        "    else:\n",
        "        images, times, center_list = Unet_test(images, model, Size_X, Size_Y)\n",
        "        save_time.append(times)\n",
        "        for i in range(batch_size//2):\n",
        "            left_result = images[i*2].astype(np.uint8)    \n",
        "            right_result = images[i*2+1].astype(np.uint8)\n",
        "            result = np.concatenate((left_result, right_result), axis = 1)\n",
        "            out.write(result)\n",
        "            # cv2_imshow(result)\n",
        "            left_center_list = (center_list[i*2][0], center_list[i*2][1])\n",
        "            right_center_list = (center_list[i*2+1][0], center_list[i*2+1][1])\n",
        " \n",
        "            left_center_list_H.append(left_center_list[1])\n",
        "            left_center_list_V.append(left_center_list[0])\n",
        "            right_center_list_H.append(right_center_list[1])\n",
        "            right_center_list_V.append(right_center_list[0])\n",
        "            t.append(frame_count/2+i)\n",
        "  \n",
        "        frame_count +=batch_size\n",
        "        images = []\n",
        "        counter = 0\n",
        "        data['Right'].update({'Horizontal': np.array(left_center_list_H)}) # this Right is for Right eye (at the left side)\n",
        "        data['Right'].update({'Vertical': np.array(left_center_list_V)})  \n",
        "        data['Left'].update({'Horizontal': np.array(right_center_list_H)}) # this Left is for Left eye (at the right side)\n",
        "        data['Left'].update({'Vertical': np.array(right_center_list_V)})\n",
        "        data.update({'Timestamps': np.array(t)})\n",
        " \n",
        "        # print(data['Left']['Horizontal'])\n",
        " \n",
        "    \n",
        "    \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break       \n",
        "    \n",
        "end_time = time.time()\n",
        "fps.append(frame_count / (end_time - start_time))\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        " \n",
        "output_video = cv2.VideoCapture(output_name)\n",
        "length = int(output_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(\"output frames = \" , length )\n",
        " \n",
        " \n",
        "cap = cv2.VideoCapture(output_name)\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(\"input frames = \" , length )\n",
        " \n",
        " \n",
        "print(\"Total time: \", (end_time - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m/content/gdrive/My Drive/codev2/trained_model/UNet/018/my_test_model_00057500iters.pt\u001b[0m\n",
            "\u001b[32mCheck point Successfully Loaded\u001b[0m\n",
            "video_name =  /content/gdrive/My Drive/codev2/Result/20210916_175947_H14_NSS16001_Test2.mp4\n",
            "output frames =  18912\n",
            "input frames =  18912\n",
            "Total time:  580.7117583751678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CybVG8Ezc-bT"
      },
      "source": [
        "# 儲存變數到pkl檔案\n",
        "import pickle\n",
        "\n",
        "# Saving the objects:\n",
        "with open(video_name[:-4]+'_unet_pixel_API.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump(data, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}