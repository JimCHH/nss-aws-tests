{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x1001000/nss-aws-tests/blob/main/colab/SPV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK_iwkijgAAB",
        "outputId": "96e4a12a-14c5-4f49-e9d9-1299bca8c663"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/gdrive') # Sign in your Google account\n",
        "# # When your key in the Authorization code, the google drive will be mounted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e9UjhPzhcky"
      },
      "source": [
        "You need to select the Test1, 2 or 3 file for computation first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM4c7QCSo2gs"
      },
      "source": [
        "# Load pkl file\n",
        "import pickle\n",
        "import glob\n",
        "\n",
        "pkl_folder = (\"/content/gdrive/My Drive/codev2/Result/\")\n",
        "pkl_list = glob.glob(pkl_folder+\"*_unet_pixel_API.pkl\")[0] # select data file\n",
        "# Getting back the objects:\n",
        "with open(pkl_list, 'rb') as f:  # Python 3: open(..., 'rb')\n",
        "   data = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC1aqnuEWJjN"
      },
      "source": [
        "All function def for Test1, 2, 3 below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU9zVnS7WcH5"
      },
      "source": [
        "# Test1, 2, 3 general function def below:\n",
        "\n",
        "def fix_blink(data):\n",
        "  zero_idx = np.where(data == 0)[0]\n",
        "  if (len(zero_idx) != 0):\n",
        "    for i in range(len(zero_idx)):\n",
        "      if (zero_idx[i] != 0):\n",
        "        data[zero_idx[i]] = data[zero_idx[i] - 1]\n",
        "    data_f = data\n",
        "  else:\n",
        "    data_f = data\n",
        "\n",
        "  return data_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDv8Gb_eCs-E"
      },
      "source": [
        "# Test1 (Spontaneous nystagmus test) & Test2 (Gaze evoked test) function def below:\n",
        "\n",
        "def isoutlier_pks(locs, pks):\n",
        "  ## Remove noise peak\n",
        "  c = 1.4826 # c=-1/(sqrt(2)*erfcinv(3/2))\n",
        "  MAD = c * np.median(abs(pks - np.median(pks)))  # MAD = c*median(abs(A-median(A)))\n",
        "  outlier_val = [x for x in pks if (x > 3 * MAD)] # ref function in matlab method \"median (default)\" https://www.mathworks.com/help/matlab/ref/isoutlier.html#bvlllts-method\n",
        "  tmp1 = []\n",
        "  for i in range(len(outlier_val)):\n",
        "    tmp = np.argwhere(pks == outlier_val[i])\n",
        "    tmp1 = np.append(tmp1, tmp)\n",
        "\n",
        "  if (tmp1 != []):\n",
        "    tmp1 = tmp1.astype(int)\n",
        "    locs_f = np.delete(locs, tmp1)\n",
        "    pks_f = np.delete(pks, tmp1)\n",
        "  else:\n",
        "    locs_f = np.delete(locs, tmp1)\n",
        "    pks_f = np.delete(pks, tmp1)\n",
        "\n",
        "  return locs_f, pks_f\n",
        "\n",
        "def Nystagmus_extract(data, Fs, medfilt1_para):\n",
        "  ## Load filter parameter\n",
        "  # Reference to paper: Pander, Tomasz, et al. \"1. .\" 2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE, 2012.\n",
        "  FIR1 = np.array(\n",
        "      [-0.0296451204833518, 0.00925172607229440, -0.0115293989022348, 0.0140375254341020, -0.0167393289436908,\n",
        "        0.0195876175466524, -0.0225259190063055, 0.0254901124852358, -0.0284104995644265, 0.0312142309050116,\n",
        "        -0.0338279828852039, 0.0361807618278533, -0.0382067031641653, 0.0398477298031179, -0.0410559384117443,\n",
        "        0.0417955941208891, 1.00907118633193, 0.0417955941208891, -0.0410559384117443, 0.0398477298031179,\n",
        "        -0.0382067031641653, 0.0361807618278533, -0.0338279828852039, 0.0312142309050116, -0.0284104995644265,\n",
        "        0.0254901124852358, -0.0225259190063055, 0.0195876175466524, -0.0167393289436908, 0.0140375254341020,\n",
        "        -0.0115293989022348, 0.00925172607229440, -0.0296451204833518])\n",
        "  FIR2 = np.array(\n",
        "      [0.0126790233155853, 0.00260959042439373, 0.00357784368011279, 0.00457039817392485, 0.00553924417565522,\n",
        "        0.00642922548646735, 0.00717965385859548, 0.00772634931826725, 0.00800404249455777, 0.00794905231651221,\n",
        "        0.00750213284050330, 0.00661136771684943, 0.00523498092281557, 0.00334392865357511, 0.000924140148254810,\n",
        "        -0.00202171512828932, -0.00547304034574246, -0.00939078846528278, -0.0137176607555862, -0.0183790526975593,\n",
        "        -0.0232847398817529, -0.0283312622978241, -0.0334049321297642, -0.0383853594960468, -0.0431493641058940,\n",
        "        -0.0475751199533050, -0.0515463660886133, -0.0549565100146286, -0.0577124517959393, -0.0597379665859794,\n",
        "        -0.0609765005955555, 0.961827736572315, -0.0609765005955555, -0.0597379665859794, -0.0577124517959393,\n",
        "        -0.0549565100146286, -0.0515463660886133, -0.0475751199533050, -0.0431493641058940, -0.0383853594960468,\n",
        "        -0.0334049321297642, -0.0283312622978241, -0.0232847398817529, -0.0183790526975593, -0.0137176607555862,\n",
        "        -0.00939078846528278, -0.00547304034574246, -0.00202171512828932, 0.000924140148254810, 0.00334392865357511,\n",
        "        0.00523498092281557, 0.00661136771684943, 0.00750213284050330, 0.00794905231651221, 0.00800404249455777,\n",
        "        0.00772634931826725, 0.00717965385859548, 0.00642922548646735, 0.00553924417565522, 0.00457039817392485,\n",
        "        0.00357784368011279, 0.00260959042439373, 0.0126790233155853])\n",
        "  FIR3 = np.array(\n",
        "      [0.0166161054134519, -0.00210022371807598, 0.00177986913220994, -0.00133019530735843, 0.000740011376541466,\n",
        "        -1.91201881788006e-17, -0.000896901583959258, 0.00195515458409058, -0.00317631732882165, 0.00455880033204366,\n",
        "        -0.00609768730834985, 0.00778463016723917, -0.00960782418992972, 0.0115520675165402, -0.0135989068041230,\n",
        "        0.0157268685236960, -0.0179117729190226, 0.0201271252267365, -0.0223445764326939, 0.0245344436876570,\n",
        "        -0.0266662785968899, 0.0287094699966587, -0.0306338665908435, 0.0324104039869497, -0.0340117202744467,\n",
        "        0.0354127443476540, -0.0365912416941331, 0.0375283033368980, -0.0382087650095708, 0.0386215454190648,\n",
        "        0.930237469421573, 0.0386215454190648, -0.0382087650095708, 0.0375283033368980, -0.0365912416941331,\n",
        "        0.0354127443476540, -0.0340117202744467, 0.0324104039869497, -0.0306338665908435, 0.0287094699966587,\n",
        "        -0.0266662785968899, 0.0245344436876570, -0.0223445764326939, 0.0201271252267365, -0.0179117729190226,\n",
        "        0.0157268685236960, -0.0135989068041230, 0.0115520675165402, -0.00960782418992972, 0.00778463016723917,\n",
        "        -0.00609768730834985, 0.00455880033204366, -0.00317631732882165, 0.00195515458409058, -0.000896901583959258,\n",
        "        -1.91201881788006e-17, 0.000740011376541466, -0.00133019530735843, 0.00177986913220994, -0.00210022371807598,\n",
        "        0.0166161054134519])\n",
        "\n",
        "  ## Preprocessing stage\n",
        "  data_m = data - np.mean(data)\n",
        "  data1 = stats.zscore(data_m)\n",
        "  data2 = signal.medfilt(data1, medfilt1_para)  # median filter\n",
        "  # Use lfilter to filter x with the FIR filter.\n",
        "  data3 = filtfilt(FIR1, 1, data2)  # The low-pass filtering with fcut-off = 30 Hz realized as the 32th order low-pass FIR filter.\n",
        "  data4 = filtfilt(FIR2, 1, data3)  # The high-pass filtering with fcut-off = 1.5 Hz applying the Chebyshev window with 20 dB of relative sidelobe attenuation is also used. The order of the filter is 62.\n",
        "  data5 = filtfilt(FIR3, 1, data4)  # The low-pass FIR filtering with fcut-off = 25 Hz realized as the 60th order low-pass FIR filter and the Chebyshev window with 20 dB of relative sidelobe attenuation is also used.\n",
        "\n",
        "  ## Non-linear operation\n",
        "  data6 = np.power(np.diff(data5), 2)\n",
        "\n",
        "  ## Peak detection\n",
        "  # Nystagmus waveform last as high as 350 ms / mean is 250 ms\n",
        "  locs, properties = find_peaks(data6, prominence=0.01, distance=Fs*0.1) # distance = 250 / (1000/Fs)\n",
        "  pks = properties.get('prominences')\n",
        "  locs_f, pks_f = isoutlier_pks(locs, pks)\n",
        "\n",
        "  return locs_f, pks_f\n",
        "\n",
        "def isoutlier(data):\n",
        "  ## Remove mean outlier\n",
        "  outlier_val = [x for x in data if (x > 3 * np.std(data))]\n",
        "  tmp1 = []\n",
        "  for i in range(len(outlier_val)):\n",
        "    tmp = np.argwhere(data == outlier_val[i])\n",
        "    tmp1 = np.append(tmp1, tmp)\n",
        "  \n",
        "  if (tmp1 != []):\n",
        "    tmp1 = tmp1.astype(int)\n",
        "    data_f = np.delete(data, tmp1)\n",
        "  else:\n",
        "    data_f = np.delete(data, tmp1)\n",
        "\n",
        "  return data_f\n",
        "\n",
        "def SPV_computation(data, Interval, medfilt1_para):\n",
        "  ## Slow phase detection\n",
        "  data_m = data - np.mean(data)\n",
        "  # true for all elements more than three local scaled MAD from the local median\n",
        "  c = 1.4826 # c=-1/(sqrt(2)*erfcinv(3/2))\n",
        "  MAD = c * np.median(abs(np.diff(data_m) - np.median(np.diff(data_m))))  # MAD = c*median(abs(A-median(A)))\n",
        "  FP_out = np.where(abs(np.diff(data_m)) > (3 * MAD), 0, 1)\n",
        "  for i in range(1, len(FP_out) - 1):\n",
        "    if ((FP_out[i-1] & FP_out[i+1]) == 1):\n",
        "      FP_out[i] = 1\n",
        "    elif ((FP_out[i-1] | FP_out[i+1]) == 0):\n",
        "      FP_out[i] = 0\n",
        "    else:\n",
        "      FP_out[i] = FP_out[i]\n",
        "  SP_idx = np.where(FP_out)\n",
        "\n",
        "  ## Slow Phase Velocity (SPV) parameter\n",
        "  data_v = np.diff(data_m) / Interval  # for Nystagmus type classification\n",
        "  SP_v = signal.medfilt(data_v, medfilt1_para) # for SPV computation\n",
        "  SP_v_SP = SP_v[SP_idx]\n",
        "  SP_v_SP1 = isoutlier(SP_v_SP) # mean remove outlier\n",
        "  SPV_mean = np.nanmean(SP_v_SP1)\n",
        "  SPV_std = np.nanstd(SP_v_SP1)\n",
        "  SPV_med = np.nanmedian(SP_v_SP1)\n",
        "  if (SP_v_SP1 != []):\n",
        "    SPV_iqr = np.subtract(*np.percentile(SP_v_SP1, [75, 25]))\n",
        "  else:\n",
        "    SPV_iqr = float(\"nan\")\n",
        "\n",
        "  ## SPV durartion ratio\n",
        "  # Every VNG waveform (30sec), the duration of slow phase (right or up) over the duration of show phase (left or down)\n",
        "  # Modified ratio = (long duration / short duration)，high ratio is with Nystagmus，ratio is 1 without Nystagmus\n",
        "  SPVd_r = np.sum(np.where(SP_v_SP1 > 0, 1, 0))# * Interval\n",
        "  SPVd_l = np.sum(np.where(SP_v_SP1 < 0, 1, 0))# * Interval\n",
        "  if (SPVd_r >= SPVd_l):\n",
        "    SPVd_ratio = SPVd_r / SPVd_l\n",
        "  else:\n",
        "    SPVd_ratio = SPVd_l / SPVd_r\n",
        "   \n",
        "  return SPV_mean, SPV_std, SPV_med, SPV_iqr, SPVd_ratio, SP_v, SP_idx, data_m, SP_v_SP, SP_v_SP1\n",
        "  # data_m: zeromean Eye position\n",
        "  # SP_v: filtered Eye velocity\n",
        "  # SP_idx: all slow phase index in Eye position and velocity (green dot)\n",
        "  # SP_v, SP_v_SP, SP_v_SP1, data_v\n",
        "\n",
        "def Nystagmus_type(data, locs, data_type):\n",
        "  ## Nystagmus type classification\n",
        "  # data_type = 'Horizontal'\n",
        "  # data_type = 'Vertical'\n",
        "  data_m = data - np.mean(data)\n",
        "  data_v = np.diff(data_m) / Interval  # for Nystagmus type classification\n",
        "  saccade_array = np.sign(data_v[locs])\n",
        "  saccade_num_P = np.sum(np.where(saccade_array == 1, 1, 0))\n",
        "  saccade_consecnum_P = max([len(list(g)) for i, g in groupby(saccade_array) if i == 1], default = [])\n",
        "  saccade_num_N = np.sum(np.where(saccade_array == -1, 1, 0))\n",
        "  saccade_consecnum_N = max([len(list(g)) for i, g in groupby(saccade_array) if i == -1], default = [])\n",
        "  saccade_num_Z = np.sum(np.where(saccade_array == 0, 1, 0))\n",
        "  saccade_consecnum_Z = max([len(list(g)) for i, g in groupby(saccade_array) if i == 0], default = [])\n",
        "  list1 = [saccade_num_P, saccade_num_N, saccade_num_Z]\n",
        "  saccade_num_max = list1.index(max(list1))\n",
        "  if saccade_num_max == 0 and (saccade_num_N/saccade_num_P < 0.2):\n",
        "    if data_type == 'Horizontal':\n",
        "      type = 'LBN'\n",
        "    else: # 'Vertical'\n",
        "      type = 'DBN'\n",
        "  elif saccade_num_max == 1 and (saccade_num_P/saccade_num_N < 0.2):\n",
        "    if data_type == 'Horizontal':\n",
        "      type = 'RBN'\n",
        "    else: # 'Vertical'\n",
        "      type = 'UBN'\n",
        "  elif saccade_num_max == 2:\n",
        "    type = 'Unknown'\n",
        "  else:\n",
        "    type = 'Jerks'\n",
        "\n",
        "  return type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoEaDPC2QrXp"
      },
      "source": [
        "# Test2 (Gaze evoked test) function def below, but the above function need to be defined first:\n",
        "\n",
        "def ismember(locs, gaze_interval):\n",
        "  return [ np.sum(a == gaze_interval) for a in locs ]\n",
        "\n",
        "def gaze_SPV(SP_v, SP_idx):\n",
        "  SP_v_SP = SP_v[SP_idx]\n",
        "  SP_v_SP1 = isoutlier(SP_v_SP) # mean remove outlier\n",
        "  SPV_mean = np.nanmean(SP_v_SP1)\n",
        "  SPV_std = np.nanstd(SP_v_SP1)\n",
        "  SPV_med = np.nanmedian(SP_v_SP1)\n",
        "  if (SP_v_SP1 != []):\n",
        "    SPV_iqr = np.subtract(*np.percentile(SP_v_SP1, [75, 25]))\n",
        "  else:\n",
        "    SPV_iqr = float(\"nan\")\n",
        "\n",
        "  ## SPV durartion ratio\n",
        "  # Every VNG waveform (30sec), the duration of slow phase (right or up) over the duration of show phase (left or down)\n",
        "  # Modified ratio = (long duration / short duration)，high ratio is with Nystagmus，ratio is 1 without Nystagmus\n",
        "  SPVd_r = np.sum(np.where(SP_v_SP1 > 0, 1, 0))# * Interval\n",
        "  SPVd_l = np.sum(np.where(SP_v_SP1 < 0, 1, 0))# * Interval\n",
        "  if (SPVd_r >= SPVd_l):\n",
        "    SPVd_ratio = SPVd_r / SPVd_l\n",
        "  else:\n",
        "    SPVd_ratio = SPVd_l / SPVd_r\n",
        "  \n",
        "  return SPV_mean, SPV_std, SPV_med, SPV_iqr, SPVd_ratio, SP_v_SP1\n",
        "\n",
        "def gaze_interval_split(data_H, data_V):\n",
        "  # find right left up down interval (1/2*target degree, Horiztonal target degree = 15, Vertical target degree = 10)\n",
        "  center_interval = np.where((data_H <= 7.5) & (data_H >= -7.5) & (data_V <= 5) & (data_V >= -5)) \n",
        "  right_interval = np.where((data_H > 7.5)) # ignore right corner noise\n",
        "  left_interval = np.where(data_H < -7.5) # ignore leff corner noise\n",
        "  up_interval = np.where(data_V > 5) # ignore up corner noise\n",
        "  down_interval = np.where(data_V < -5) # ignore down corner noise\n",
        "\n",
        "  return center_interval, right_interval, left_interval, up_interval, down_interval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc2G04IoVcM5"
      },
      "source": [
        "# Test3 (Skew deviation (CUT) test) function def below:\n",
        "\n",
        "## CUT function skew deviation\n",
        "# Avg Eye Position Shift (°) – the average eye position deviation (for the horizontal and vertical traces) when the condition changes between the eye being covered and uncovered.\n",
        "def skewD(data):\n",
        "  skew_deviation = np.subtract(*np.percentile(data, [90, 10]))\n",
        "\n",
        "  return skew_deviation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1koxcVdV1g1"
      },
      "source": [
        "Main script below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgLKA6U3OyNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f64c21e-ba78-41e9-9cc9-2fb972e0a359"
      },
      "source": [
        "### Main code\n",
        "### Import function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import scipy.signal as signal\n",
        "from scipy.signal import filtfilt\n",
        "from scipy.signal import find_peaks\n",
        "from itertools import groupby\n",
        "\n",
        "## System parameter setting\n",
        "# Predefined video fps\n",
        "Fs = 210 # 222 for EyeSeeCam\n",
        "Interval = 1/210 # 222 for EyeSeeCam\n",
        "medfilt1_para = 11 # filter parameter\n",
        "T = data['Timestamps'] # load timestamps from data dictionary\n",
        "total_time = len(T)/210 # data time (sec)\n",
        "saccade_interval = (T[-1] / 210) / 10 # num/10s, T[-1]=total frame\n",
        "\n",
        "\n",
        "input_test_name = pkl_list.split('_')[-4] # split string by '_' and output the last 4th string array\n",
        "\n",
        "if (input_test_name == 'Test1') or (input_test_name == 'Test2'):\n",
        "  ## output all dictionary data\n",
        "  saccade_num_dict = {'Left': {}, 'Right':{}}\n",
        "  saccade_num_FR_dict = {'Left': {}, 'Right':{}}\n",
        "  SPV_mean_dict = {'Left': {}, 'Right':{}}\n",
        "  SPV_std_dict = {'Left': {}, 'Right':{}}\n",
        "  SPV_med_dict = {'Left': {}, 'Right':{}}\n",
        "  SPV_iqr_dict = {'Left': {}, 'Right':{}}\n",
        "  SPVd_ratio_dict = {'Left': {}, 'Right':{}}\n",
        "  data_m_dict = {'Left': {}, 'Right':{}}\n",
        "  SP_v_dict = {'Left': {}, 'Right':{}}\n",
        "  SP_idx_dict = {'Left': {}, 'Right':{}}\n",
        "  type_dict = {'Left': {}, 'Right':{}}\n",
        "  SP_v_SP_outlier_filtered_dict = {'Left': {}, 'Right':{}}\n",
        "\n",
        "  ## Horizontal data / Vertial data as input from Left eye / Right eye\n",
        "  eye_select = ['Left', 'Right']\n",
        "  dir_select = ['Horizontal', 'Vertical']\n",
        "  for eye_key in eye_select:\n",
        "    for dir_key in dir_select:\n",
        "      ## VNG data fix zero value\n",
        "      data_f = fix_blink(data[eye_key][dir_key])\n",
        "      \n",
        "      ## Nystagmus trial detection\n",
        "      locs, pks = Nystagmus_extract(data_f, Fs, medfilt1_para)\n",
        "      saccade_num = len(locs)\n",
        "      saccade_num_FR = saccade_num / saccade_interval\n",
        "      \n",
        "      ## SPV parameter computation\n",
        "      SPV_mean, SPV_std, SPV_med, SPV_iqr, SPVd_ratio, SP_v, SP_idx, data_m, SP_v_SP, SP_v_SP1 = SPV_computation(data_f, Interval, medfilt1_para)\n",
        "\n",
        "      ## Nystagmus type classification\n",
        "      type = Nystagmus_type(data_f, locs, dir_key) # data_type use \"Horizontal\" or \"Vertical\"\n",
        "\n",
        "      ## Updata dictionary data\n",
        "      saccade_num_dict[eye_key].update({dir_key: saccade_num})\n",
        "      saccade_num_FR_dict[eye_key].update({dir_key: saccade_num_FR})\n",
        "      SPV_mean_dict[eye_key].update({dir_key: SPV_mean})\n",
        "      SPV_std_dict[eye_key].update({dir_key: SPV_std})\n",
        "      SPV_med_dict[eye_key].update({dir_key: SPV_med})\n",
        "      SPV_iqr_dict[eye_key].update({dir_key: SPV_iqr})\n",
        "      SPVd_ratio_dict[eye_key].update({dir_key: SPVd_ratio})\n",
        "      data_m_dict[eye_key].update({dir_key: data_m})\n",
        "      SP_v_dict[eye_key].update({dir_key: SP_v})\n",
        "      SP_v_SP_outlier_filtered_dict[eye_key].update({dir_key: SP_v_SP1})\n",
        "      SP_idx_dict[eye_key].update({dir_key: SP_idx})\n",
        "      type_dict[eye_key].update({dir_key: type})\n",
        "\n",
        "  if input_test_name == 'Test2':\n",
        "    ## output all dictionary data\n",
        "    # Center\n",
        "    saccade_num_center_dict = {'Left': {}, 'Right':{}}\n",
        "    saccade_num_FR_center_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_mean_center_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_std_center_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_med_center_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_iqr_center_dict = {'Left': {}, 'Right':{}}\n",
        "    SPVd_ratio_center_dict = {'Left': {}, 'Right':{}}\n",
        "    SP_v_SP_outlier_filtered_center_dict = {'Left': {}, 'Right':{}}\n",
        "    # Right\n",
        "    saccade_num_right_dict = {'Left': {}, 'Right':{}}\n",
        "    saccade_num_FR_right_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_mean_right_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_std_right_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_med_right_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_iqr_right_dict = {'Left': {}, 'Right':{}}\n",
        "    SPVd_ratio_right_dict = {'Left': {}, 'Right':{}}\n",
        "    SP_v_SP_outlier_filtered_right_dict = {'Left': {}, 'Right':{}}\n",
        "    # Left\n",
        "    saccade_num_left_dict = {'Left': {}, 'Right':{}}\n",
        "    saccade_num_FR_left_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_mean_left_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_std_left_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_med_left_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_iqr_left_dict = {'Left': {}, 'Right':{}}\n",
        "    SPVd_ratio_left_dict = {'Left': {}, 'Right':{}}\n",
        "    SP_v_SP_outlier_filtered_left_dict = {'Left': {}, 'Right':{}}\n",
        "    # Up\n",
        "    saccade_num_up_dict = {'Left': {}, 'Right':{}}\n",
        "    saccade_num_FR_up_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_mean_up_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_std_up_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_med_up_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_iqr_up_dict = {'Left': {}, 'Right':{}}\n",
        "    SPVd_ratio_up_dict = {'Left': {}, 'Right':{}}\n",
        "    SP_v_SP_outlier_filtered_up_dict = {'Left': {}, 'Right':{}}\n",
        "    # Down\n",
        "    saccade_num_down_dict = {'Left': {}, 'Right':{}}\n",
        "    saccade_num_FR_down_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_mean_down_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_std_down_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_med_down_dict = {'Left': {}, 'Right':{}}\n",
        "    SPV_iqr_down_dict = {'Left': {}, 'Right':{}}\n",
        "    SPVd_ratio_down_dict = {'Left': {}, 'Right':{}}\n",
        "    SP_v_SP_outlier_filtered_down_dict = {'Left': {}, 'Right':{}}\n",
        "\n",
        "\n",
        "    ## Horizontal data / Vertial data as input from Left eye / Right eye\n",
        "    eye_select = ['Left', 'Right']\n",
        "    dir_select = ['Horizontal', 'Vertical']\n",
        "    for eye_key in eye_select:\n",
        "      ## VNG data fix zero value\n",
        "      data_f0 = fix_blink(data[eye_key][dir_select[0]])\n",
        "      data_f1 = fix_blink(data[eye_key][dir_select[1]])\n",
        "\n",
        "      center_interval, right_interval, left_interval, up_interval, down_interval = gaze_interval_split(data_f0, data_f1)\n",
        "      SP_idx_center = np.intersect1d(SP_idx, center_interval)\n",
        "      SP_idx_right = np.intersect1d(SP_idx, right_interval)\n",
        "      SP_idx_left = np.intersect1d(SP_idx, left_interval)\n",
        "      SP_idx_up = np.intersect1d(SP_idx, up_interval)\n",
        "      SP_idx_down = np.intersect1d(SP_idx, down_interval)\n",
        "\n",
        "      for dir_key in dir_select:\n",
        "        ## VNG data fix zero value\n",
        "        data_f = fix_blink(data[eye_key][dir_key])\n",
        "\n",
        "        ## Nystagmus trial detection\n",
        "        locs, pks = Nystagmus_extract(data_f, Fs, medfilt1_para)\n",
        "\n",
        "        ## SPV parameter computation\n",
        "        SPV_mean, SPV_std, SPV_med, SPV_iqr, SPVd_ratio, SP_v, SP_idx, data_m, SP_v_SP, SP_v_SP1 = SPV_computation(data_f, Interval, medfilt1_para)\n",
        "        \n",
        "        # Gaze SPV parameter computation\n",
        "        SPV_mean_center, SPV_std_center, SPV_med_center, SPV_iqr_center, SPVd_ratio_center, SP_v_SP1_center = gaze_SPV(SP_v, SP_idx_center)\n",
        "        SPV_mean_right, SPV_std_right, SPV_med_right, SPV_iqr_right, SPVd_ratio_right, SP_v_SP1_right = gaze_SPV(SP_v, SP_idx_right)\n",
        "        SPV_mean_left, SPV_std_left, SPV_med_left, SPV_iqr_left, SPVd_ratio_left, SP_v_SP1_left = gaze_SPV(SP_v, SP_idx_left)\n",
        "        SPV_mean_up, SPV_std_up, SPV_med_up, SPV_iqr_up, SPVd_ratio_up, SP_v_SP1_up = gaze_SPV(SP_v, SP_idx_up)\n",
        "        SPV_mean_down, SPV_std_down, SPV_med_down, SPV_iqr_down, SPVd_ratio_down, SP_v_SP1_down = gaze_SPV(SP_v, SP_idx_down)\n",
        "\n",
        "        # Gaze Nystagmus trial detection\n",
        "        saccade_num_center = np.sum(ismember(locs, SP_idx_center))\n",
        "        saccade_num_right = np.sum(ismember(locs, SP_idx_right))\n",
        "        saccade_num_left = np.sum(ismember(locs, SP_idx_left))\n",
        "        saccade_num_up = np.sum(ismember(locs, SP_idx_up))\n",
        "        saccade_num_down = np.sum(ismember(locs, SP_idx_down))\n",
        "        saccade_num_FR_center = saccade_num_center / saccade_interval\n",
        "        saccade_num_FR_right = saccade_num_right / saccade_interval\n",
        "        saccade_num_FR_left = saccade_num_left / saccade_interval\n",
        "        saccade_num_FR_up = saccade_num_up / saccade_interval\n",
        "        saccade_num_FR_down = saccade_num_down / saccade_interval\n",
        "      \n",
        "        ## Update dictionary data\n",
        "        # Center\n",
        "        saccade_num_center_dict[eye_key].update({dir_key: saccade_num_center})\n",
        "        saccade_num_FR_center_dict[eye_key].update({dir_key: saccade_num_FR_center})\n",
        "        SPV_mean_center_dict[eye_key].update({dir_key: SPV_mean_center})\n",
        "        SPV_std_center_dict[eye_key].update({dir_key: SPV_std_center})\n",
        "        SPV_med_center_dict[eye_key].update({dir_key: SPV_med_center})\n",
        "        SPV_iqr_center_dict[eye_key].update({dir_key: SPV_iqr_center})\n",
        "        SPVd_ratio_center_dict[eye_key].update({dir_key: SPVd_ratio_center})\n",
        "        SP_v_SP_outlier_filtered_center_dict[eye_key].update({dir_key: SP_v_SP1_center})\n",
        "        # Right\n",
        "        saccade_num_right_dict[eye_key].update({dir_key: saccade_num_right})\n",
        "        saccade_num_FR_right_dict[eye_key].update({dir_key: saccade_num_FR_right})\n",
        "        SPV_mean_right_dict[eye_key].update({dir_key: SPV_mean_right})\n",
        "        SPV_std_right_dict[eye_key].update({dir_key: SPV_std_right})\n",
        "        SPV_med_right_dict[eye_key].update({dir_key: SPV_med_right})\n",
        "        SPV_iqr_right_dict[eye_key].update({dir_key: SPV_iqr_right})\n",
        "        SPVd_ratio_right_dict[eye_key].update({dir_key: SPVd_ratio_right})\n",
        "        SP_v_SP_outlier_filtered_right_dict[eye_key].update({dir_key: SP_v_SP1_right})\n",
        "        # Left\n",
        "        saccade_num_left_dict[eye_key].update({dir_key: saccade_num_left})\n",
        "        saccade_num_FR_left_dict[eye_key].update({dir_key: saccade_num_FR_left})\n",
        "        SPV_mean_left_dict[eye_key].update({dir_key: SPV_mean_left})\n",
        "        SPV_std_left_dict[eye_key].update({dir_key: SPV_std_left})\n",
        "        SPV_med_left_dict[eye_key].update({dir_key: SPV_med_left})\n",
        "        SPV_iqr_left_dict[eye_key].update({dir_key: SPV_iqr_left})\n",
        "        SPVd_ratio_left_dict[eye_key].update({dir_key: SPVd_ratio_left})\n",
        "        SP_v_SP_outlier_filtered_left_dict[eye_key].update({dir_key: SP_v_SP1_left})\n",
        "        # Up\n",
        "        saccade_num_up_dict[eye_key].update({dir_key: saccade_num_up})\n",
        "        saccade_num_FR_up_dict[eye_key].update({dir_key: saccade_num_FR_up})\n",
        "        SPV_mean_up_dict[eye_key].update({dir_key: SPV_mean_up})\n",
        "        SPV_std_up_dict[eye_key].update({dir_key: SPV_std_up})\n",
        "        SPV_med_up_dict[eye_key].update({dir_key: SPV_med_up})\n",
        "        SPV_iqr_up_dict[eye_key].update({dir_key: SPV_iqr_up})\n",
        "        SPVd_ratio_up_dict[eye_key].update({dir_key: SPVd_ratio_up})\n",
        "        SP_v_SP_outlier_filtered_up_dict[eye_key].update({dir_key: SP_v_SP1_up})\n",
        "        # Down\n",
        "        saccade_num_down_dict[eye_key].update({dir_key: saccade_num_down})\n",
        "        saccade_num_FR_down_dict[eye_key].update({dir_key: saccade_num_FR_down})\n",
        "        SPV_mean_down_dict[eye_key].update({dir_key: SPV_mean_down})\n",
        "        SPV_std_down_dict[eye_key].update({dir_key: SPV_std_down})\n",
        "        SPV_med_down_dict[eye_key].update({dir_key: SPV_med_down})\n",
        "        SPV_iqr_down_dict[eye_key].update({dir_key: SPV_iqr_down})\n",
        "        SPVd_ratio_down_dict[eye_key].update({dir_key: SPVd_ratio_down})\n",
        "        SP_v_SP_outlier_filtered_down_dict[eye_key].update({dir_key: SP_v_SP1_down})\n",
        "\n",
        "    # Test2 for Saving the objects:\n",
        "    with open(pkl_list[:-19]+'_sp_dataset_API.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "        pickle.dump([SPV_mean_dict, SPV_std_dict, SPV_med_dict, SPV_iqr_dict, SPVd_ratio_dict, saccade_num_dict, saccade_num_FR_dict, T, data_m_dict, SP_v_dict, SP_v_SP_outlier_filtered_dict, SP_idx_dict,\n",
        "                    SPV_mean_center_dict, SPV_std_center_dict, SPV_med_center_dict, SPV_iqr_center_dict, SPVd_ratio_center_dict, saccade_num_center_dict, saccade_num_FR_center_dict, center_interval, SP_v_SP_outlier_filtered_center_dict,\n",
        "                    SPV_mean_right_dict, SPV_std_right_dict, SPV_med_right_dict, SPV_iqr_right_dict, SPVd_ratio_right_dict, saccade_num_right_dict, saccade_num_FR_right_dict, right_interval, SP_v_SP_outlier_filtered_right_dict,\n",
        "                    SPV_mean_left_dict, SPV_std_left_dict, SPV_med_left_dict, SPV_iqr_left_dict, SPVd_ratio_left_dict, saccade_num_left_dict, saccade_num_FR_left_dict, left_interval, SP_v_SP_outlier_filtered_left_dict,\n",
        "                    SPV_mean_up_dict, SPV_std_up_dict, SPV_med_up_dict, SPV_iqr_up_dict, SPVd_ratio_up_dict, saccade_num_up_dict, saccade_num_FR_up_dict, up_interval, SP_v_SP_outlier_filtered_up_dict,\n",
        "                    SPV_mean_down_dict, SPV_std_down_dict, SPV_med_down_dict, SPV_iqr_down_dict, SPVd_ratio_down_dict, saccade_num_down_dict, saccade_num_FR_down_dict, down_interval, SP_v_SP_outlier_filtered_down_dict], f)\n",
        "\n",
        "  else:\n",
        "    # Test1 for Saving the objects:\n",
        "    with open(pkl_list[:-19]+'_sp_dataset_API.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "        pickle.dump([SPV_mean_dict, SPV_std_dict, SPV_med_dict, SPV_iqr_dict, SPVd_ratio_dict, \n",
        "                    saccade_num_dict, saccade_num_FR_dict, T, data_m_dict, \n",
        "                    SP_v_dict, SP_v_SP_outlier_filtered_dict, SP_idx_dict], f)\n",
        "\n",
        "else: \n",
        "  # if input_test_name == 'Test3'\n",
        "  ## output all dictionary data\n",
        "  data_m_dict = {'Left': {}, 'Right':{}}\n",
        "  skew_deviation_dict = {'Left': {}, 'Right':{}}\n",
        "\n",
        "  ## Horizontal data / Vertial data as input from Left eye / Right eye\n",
        "  eye_select = ['Left', 'Right']\n",
        "  dir_select = ['Horizontal', 'Vertical']\n",
        "  for eye_key in eye_select:\n",
        "    for dir_key in dir_select:\n",
        "      ## VNG data fix zero value\n",
        "      data_f = fix_blink(data[eye_key][dir_key])\n",
        "      \n",
        "      ## Preprocessing stage for zero mean\n",
        "      data_m = data_f - np.mean(data_f)\n",
        "\n",
        "      ## Compute Skew deviation for angle diffrence\n",
        "      skew_deviation = skewD(data_m)\n",
        "\n",
        "      ## Updata dictionary data\n",
        "      data_m_dict[eye_key].update({dir_key: data_m})\n",
        "      skew_deviation_dict[eye_key].update({dir_key: skew_deviation})\n",
        "\n",
        "  # Test3 for Saving the objects:\n",
        "  with open(pkl_list[:-19]+'_sp_dataset_API.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "      pickle.dump([skew_deviation_dict, T, data_m_dict], f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:91: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:159: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: Mean of empty slice\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1665: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
            "  keepdims=keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLrNBwUAg84K"
      },
      "source": [
        "Below sample code for how to combined for padas format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AIvZCWcD_Fh"
      },
      "source": [
        "# ## Test1, Test2 Show result in table\n",
        "# result = [[SPV_mean_dict['Left']['Horizontal'], SPV_std_dict['Left']['Horizontal'], SPV_med_dict['Left']['Horizontal'], SPV_iqr_dict['Left']['Horizontal'], SPVd_ratio_dict['Left']['Horizontal'], saccade_num_dict['Left']['Horizontal'], saccade_num_FR_dict['Left']['Horizontal'], type_dict['Left']['Horizontal']], \n",
        "#       [SPV_mean_dict['Left']['Vertical'],  SPV_std_dict['Left']['Vertical'],  SPV_med_dict['Left']['Vertical'],  SPV_iqr_dict['Left']['Vertical'],  SPVd_ratio_dict['Left']['Vertical'],  saccade_num_dict['Left']['Vertical'],  saccade_num_FR_dict['Left']['Vertical'],  type_dict['Left']['Vertical']], \n",
        "#       [SPV_mean_dict['Right']['Horizontal'], SPV_std_dict['Right']['Horizontal'],SPV_med_dict['Right']['Horizontal'], SPV_iqr_dict['Right']['Horizontal'],SPVd_ratio_dict['Right']['Horizontal'], saccade_num_dict['Right']['Horizontal'],saccade_num_FR_dict['Right']['Horizontal'], type_dict['Right']['Horizontal']], \n",
        "#       [SPV_mean_dict['Right']['Vertical'], SPV_std_dict['Right']['Vertical'], SPV_med_dict['Right']['Vertical'], SPV_iqr_dict['Right']['Vertical'], SPVd_ratio_dict['Right']['Vertical'], saccade_num_dict['Right']['Vertical'], saccade_num_FR_dict['Right']['Vertical'], type_dict['Right']['Vertical']]]\n",
        "\n",
        "# headersX = [\"Left Horizontal\", \"Left Vertical\", \"Right Horizontal\", \"Right Vertical\"]\n",
        "# headersY = [\"SPV_mean\", \"SPV_std\", \"SPV_med\", \"SPV_iqr\", \"SPVd_ratio\", \"saccade_num\", \"saccade_num_FR\", \"type\"]\n",
        "# print(pd.DataFrame(result, headersX, headersY))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}